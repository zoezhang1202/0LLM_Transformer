{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffce855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_quaternion_mul(kernel, concat_dim=0):\n",
    "    r, i, j, k = torch.chunk(kernel, 4, dim=-1)\n",
    "    r2 = torch.cat([r, -i, -j, -k], dim=-1)\n",
    "    i2 = torch.cat([i, r, -k, j], dim=-1)\n",
    "    j2 = torch.cat([j, k, r, -i], dim=-1)\n",
    "    k2 = torch.cat([k, -j, i, r], dim=-1)\n",
    "    hamilton = torch.cat([r2, i2, j2, k2], dim=concat_dim)\n",
    "    return hamilton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91597c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r(x, dim=1):\n",
    "    return torch.chunk(x, 4, dim=dim)[0]\n",
    "\n",
    "def get_i(x, dim=1):\n",
    "    return torch.chunk(x, 4, dim=dim)[1]\n",
    "\n",
    "def get_j(x, dim=1):\n",
    "    return torch.chunk(x, 4, dim=dim)[2]\n",
    "\n",
    "def get_k(x, dim=1):\n",
    "    return torch.chunk(x, 4, dim=dim)[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ac4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_attention(a, b):\n",
    "    \"\"\"Performs dot product attention between two quaternion sequences.\"\"\"\n",
    "    print(\"light Attention!\")\n",
    "    print(a)\n",
    "    print(b)\n",
    "    \n",
    "    ar, ai, aj, ak = torch.chunk(a, 4, dim=-1)\n",
    "    br, bi, bj, bk = torch.chunk(b, 4, dim=-1)\n",
    "    \n",
    "    r = torch.matmul(ar, br.transpose(-2, -1)) - torch.matmul(ai, bi.transpose(-2, -1)) - torch.matmul(aj, bj.transpose(-2, -1)) - torch.matmul(ak, bk.transpose(-2, -1))\n",
    "    i = torch.matmul(ar, bi.transpose(-2, -1)) + torch.matmul(ai, br.transpose(-2, -1)) + torch.matmul(aj, bk.transpose(-2, -1)) - torch.matmul(ak, bj.transpose(-2, -1))\n",
    "    j = torch.matmul(ar, bj.transpose(-2, -1)) - torch.matmul(ai, bk.transpose(-2, -1)) + torch.matmul(aj, br.transpose(-2, -1)) + torch.matmul(ak, bi.transpose(-2, -1))\n",
    "    k = torch.matmul(ar, bk.transpose(-2, -1)) + torch.matmul(ai, bj.transpose(-2, -1)) - torch.matmul(aj, bi.transpose(-2, -1)) + torch.matmul(ak, br.transpose(-2, -1))\n",
    "    \n",
    "    return [r, i, j, k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_dot_product_att(a, b):\n",
    "    \"\"\"Wrapper for two sequences.\"\"\"\n",
    "    al = a.shape[1]\n",
    "    bl = b.shape[1]\n",
    "    d = a.shape[2]\n",
    "    bsz = b.shape[0]\n",
    "    \n",
    "    a = a.view(-1, d)\n",
    "    a = a.repeat(bl, 1)\n",
    "    b = b.view(-1, d)\n",
    "    b = b.repeat(al, 1)\n",
    "    \n",
    "    att = quaternion_dot(a, b)\n",
    "    att = att.view(bsz, -1, al * bl)\n",
    "    att = torch.sum(att, dim=1)\n",
    "    \n",
    "    return att.view(-1, al * bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_dot_3d(q0, q1):\n",
    "    d = q0.shape[2]\n",
    "    sq = q0.shape[1]\n",
    "    \n",
    "    q0 = q0.view(-1, d)\n",
    "    q1 = q1.view(-1, d)\n",
    "    \n",
    "    out = quaternion_dot(q0, q1)\n",
    "    return out.view(-1, sq, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_dot(q0, q1):\n",
    "    \"\"\"Quaternion product between 2 quaternions.\"\"\"\n",
    "    q1_r = get_r(q1)\n",
    "    q1_i = get_i(q1)\n",
    "    q1_j = get_j(q1)\n",
    "    q1_k = get_k(q1)\n",
    "    \n",
    "    r_base = q0 * q1\n",
    "    r = get_r(r_base) - get_i(r_base) - get_j(r_base) - get_k(r_base)\n",
    "    \n",
    "    i_base = q0 * torch.cat([q1_i, q1_r, q1_k, q1_j], dim=1)\n",
    "    i = get_r(i_base) + get_i(i_base) + get_j(i_base) - get_k(i_base)\n",
    "    \n",
    "    j_base = q0 * torch.cat([q1_j, q1_k, q1_r, q1_i], dim=1)\n",
    "    j = get_r(j_base) - get_i(j_base) + get_j(j_base) + get_k(j_base)\n",
    "    \n",
    "    k_base = q0 * torch.cat([q1_k, q1_j, q1_i, q1_r], dim=1)\n",
    "    k = get_r(k_base) + get_i(k_base) - get_j(k_base) + get_k(k_base)\n",
    "    \n",
    "    return torch.cat([r, i, j, k], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba65887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_concat(x, dim):\n",
    "    \"\"\"Concatenates quaternion components individually.\"\"\"\n",
    "    output = [[] for _ in range(4)]\n",
    "    for _x in x:\n",
    "        sp = torch.chunk(_x, 4, dim=dim)\n",
    "        for i in range(4):\n",
    "            output[i].append(sp[i])\n",
    "    \n",
    "    final = []\n",
    "    for o in output:\n",
    "        o = torch.cat(o, dim)\n",
    "        final.append(o)\n",
    "    \n",
    "    return torch.cat(final, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_ffn_3d(x, dim, num_layers=1, activation=None):\n",
    "    \"\"\"Quaternion Feed-forward layers to 3D input [bsz x seq_len x dim].\"\"\"\n",
    "    print(\"QFFN layer..\")\n",
    "    _d = x.shape[2]\n",
    "    sq = x.shape[1]\n",
    "    \n",
    "    x = x.view(-1, _d)\n",
    "    x = quaternion_ffn(x, dim, num_layers=num_layers, activation=activation)\n",
    "    return x.view(-1, sq, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfe34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_ffn(x, dim, num_layers=1, activation=None):\n",
    "    \"\"\"Implements quaternion feed-forward layer.\"\"\"\n",
    "    input_dim = x.shape[1] // 4\n",
    "    kernel = torch.nn.Parameter(torch.randn(input_dim, dim))\n",
    "    hamilton = make_quaternion_mul(kernel)\n",
    "    \n",
    "    output = torch.matmul(x, hamilton)\n",
    "    if activation:\n",
    "        output = activation(output)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd78ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamilton_product(x, kernel):\n",
    "    h = make_quaternion_mul(kernel)\n",
    "    return torch.matmul(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b92cabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QFFN layer..\n",
      "Input:\n",
      "tensor([[[-0.4064,  0.2875,  0.6615, -0.9883, -0.9946, -0.4287,  1.1147,\n",
      "          -0.1516],\n",
      "         [-0.8567, -0.8068, -0.3999,  1.5470, -0.4792, -0.7334,  0.3172,\n",
      "          -0.5948],\n",
      "         [-1.3753, -1.3093, -0.9861,  0.3092, -0.3756,  0.4984, -0.0749,\n",
      "          -0.0754],\n",
      "         [ 0.5036,  2.2707, -0.7800,  0.6164,  0.7807, -1.1588,  1.3719,\n",
      "          -2.5887],\n",
      "         [ 0.3680, -1.6838, -0.9956, -0.4719,  0.6074, -0.0849, -0.6777,\n",
      "           1.5089]],\n",
      "\n",
      "        [[ 0.7396,  0.4635, -0.3600,  0.2646,  1.5537,  0.8283,  0.9151,\n",
      "           1.2679],\n",
      "         [ 0.8087,  0.8427,  0.1244,  0.3937,  0.6388, -1.5309,  0.5833,\n",
      "          -1.2415],\n",
      "         [-1.1429, -1.2020, -0.6896, -0.1691,  0.3244, -1.3988, -1.2236,\n",
      "          -0.3101],\n",
      "         [ 1.5469,  0.0957,  1.2384, -0.4310,  1.6011,  1.6669,  0.5646,\n",
      "           1.3517],\n",
      "         [ 0.3872,  0.1423, -1.6086, -0.9811, -0.0216,  0.1643,  1.1826,\n",
      "           1.5435]]])\n",
      "\n",
      "FFN Output:\n",
      "tensor([[[-0.7941, -0.6765, -2.3659,  0.8463, -1.5348,  1.3820, -1.1536,\n",
      "           0.5206],\n",
      "         [ 1.8902,  2.3777, -2.9255,  1.0023, -0.8794, -1.8935,  0.1878,\n",
      "          -2.4220],\n",
      "         [ 2.3877,  0.2938, -1.9666,  1.9842,  0.8937, -3.1724,  0.8302,\n",
      "          -1.9277],\n",
      "         [ 1.2240,  0.1591, -1.1520, -4.9610, -2.3671,  0.1377,  0.1404,\n",
      "           0.2192],\n",
      "         [ 2.6170, -0.3475,  3.0426,  2.7470,  2.2734, -2.4421,  1.2240,\n",
      "           1.6531]],\n",
      "\n",
      "        [[ 2.3164, -3.0456,  3.2984, -0.0419, -1.8572,  0.9237,  0.6472,\n",
      "          -0.6251],\n",
      "         [-0.0368,  1.1775,  0.1388, -2.7534, -1.5498,  0.3333,  0.6773,\n",
      "           1.1188],\n",
      "         [ 1.1425,  3.3324, -1.5705,  0.3302,  3.3555, -3.4869,  3.2206,\n",
      "           0.7567],\n",
      "         [-1.5552, -4.4855,  5.4217, -0.9053, -3.0628,  2.4902,  0.6916,\n",
      "           0.0065],\n",
      "         [ 4.4529, -2.8615,  1.6172,  3.0880,  0.4043, -0.1153, -1.7016,\n",
      "           1.7385]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "batch_size = 2\n",
    "seq_length = 5\n",
    "embed_dim = 8\n",
    "\n",
    "# Create random input tensor (batch_size, seq_length, embed_dim)\n",
    "x = torch.randn(batch_size, seq_length, embed_dim)\n",
    "\n",
    "# Apply quaternion feed-forward network\n",
    "ffn_output = quaternion_ffn_3d(x, dim=embed_dim)\n",
    "print(\"Input:\")\n",
    "print(x)\n",
    "print(\"\\nFFN Output:\")\n",
    "print(ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e472ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
